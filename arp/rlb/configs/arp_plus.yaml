py_module: autoregressive_policy_plus

model:
  weights: null 
  # weights: /opt/data/private/arp/arp/rlb/outputs/arp_plus_moe_1gate/lr1.75e-05/10wE/2024-12-24_17-15/model_75000.pth

  hp:
    # rot_z_weight_factor: 1
    # rot_z_weight_max: 2
    is_moe: true # true
    moe_weight: 0.5 #2 
    moe:
      multiple_gate: True # false
      num_experts: 4 #16 #8
      k: 1 #2 #4 #可以试一下1，以及留一个num_moe_layers的接口
      num_shared_experts: 0 # not available yet
    add_corr: true
    add_depth: true
    add_lang: true
    add_pixel_loc: true
    add_proprio: true
    attn_dim: 512
    attn_dim_head: 64
    attn_dropout: 0.1
    attn_heads: 8
    depth: 8
    feat_dim: 220 # 72*3 + 4
    im_channels: 64
    point_augment_noise: 0.05
    img_feat_dim: 3
    img_patch_size: 14
    img_size: 224
    lang_dim: 512
    lang_len: 77
    norm_corr: true
    pe_fix: true
    proprio_dim: 3 # 4 # 18
    mvt_cameras: ['top', 'left', 'front']
    stage2_zoom_scale: 4
    stage2_waypoint_label_noise: 0.05
    rotation_aug: #null
      - [-2, -1, 0, -1, -2]
      - [0.1, 0.2, 0.4, 0.2, 0.1]
    use_xformers: true

    gt_hm_sigma: 1.5
    move_pc_in_bound: true
    place_with_mean: false

    amp: True
    bnb: True

    # lr should be thought on per sample basis
    # effective lr is multiplied by bs * num_devices
    lr: 1e-4 # 1e-4 #before 1.25e-5 # 1e-4 # 在train的时候cfg.model.hp.lr *= (world_size * cfg.train.bs),少GPU应对应增大lr
    warmup_steps: 2000
    optimizer_type: lamb
    lr_cos_dec: true
    add_rgc_loss: true
    transform_augmentation: true
    transform_augmentation_xyz: [0.125, 0.125, 0.125]
    transform_augmentation_rpy: [0.0, 0.0, 45.0]
    lambda_weight_l2: 1e-4 # 1e-6
    num_rotation_classes: 72

    cos_dec_max_step: -1 # will be override during training

    render_with_cpp: true

    # arp_cfg: 
    #   TODO: true


env:
  tasks: all # stack_cups,turn_tap,open_drawer,push_buttons,slide_block_to_color_target # stack_cups, before all
  cameras: ["front", "left_shoulder", "right_shoulder", "wrist"]
  scene_bounds: [-0.3, -0.5, 0.6, 0.7, 0.5, 1.6] # [x_min, y_min, z_min, x_max, y_max, z_max] - the metric volume to be voxelized
  image_size: 128
  time_in_state: false
  voxel_size: 100
  episode_length: 25
  rotation_resolution: 5
  origin_style_state: true

train:
  bs: 48 #before 96 # 48
  demo_folder: ./data/train
  epochs: 16 # before 100 # 16
  num_gpus: 1 # before 4
  num_workers: 8 # 8, need larger value
  num_transitions_per_epoch: 80000 #160000 # iters=n*epochs/bs
  disp_freq: 100
  cached_dataset_path: null
  save_freq: 5000 # before 10000
  eval_mode: false
  k2k_sample_ratios: 
    place_cups: 1.0
    stack_cups: 1.0
    close_jar: 1.0
    push_buttons: 1.0
    meat_off_grill: 1.0
    stack_blocks: 1.0
    reach_and_drag: 1.0
    slide_block_to_color_target: 1.0
    place_shape_in_shape_sorter: 1.0
    open_drawer: 1.0
    sweep_to_dustpan_of_size: 1.0
    put_groceries_in_cupboard: 1.0
    light_bulb_in: 1.0
    turn_tap: 1.0
    insert_onto_square_peg: 1.0
    put_item_in_drawer: 1.0
    put_money_in_safe: 1.0
    place_wine_at_rack_location: 1.0

eval:
  datafolder: ./data/test
  episode_num: 25
  start_episode: 0
  headless: true
  save_video: false
  device: 0


# ================================================ #

hydra:
  job:
    name: moe # test # default # arp_plus # eval.arp_plus
    # name: arp_plus_moe_1gate # default # arp_plus # eval.arp_plus
    chdir: false
  run:
    # dir: outputs/${hydra.job.name}/lr${model.hp.lr}/moe${model.hp.is_moe}/dubug
    dir: outputs/${hydra.job.name}/lr${model.hp.lr}/moe${model.hp.is_moe}/${now:%Y-%m-%d_%H-%M}
    # dir: /opt/data/private/arp/arp/rlb/outputs/arp_plus_moe_1gate/lr1.75e-05/10wE/2024-12-24_17-15
  
output_dir: ${hydra:run.dir} 
# output_dir: outputs/eval.arp_plus/`date +"%Y-%m-%d_%H-%M"`+'stack_cups_16666_lr1e-4'
wandb: arp_moe # before null
